% chapters/05_sections/profiling_analysis.tex
\section{Profiling Analysis}\label{sec:profiling}

Nsight Compute data is used to explain \emph{why} performance changes after each
optimisation, not only \emph{how much} it changes.

\subsection{KPI Pack Used for Attribution}

To keep profiling interpretable and comparable, all Nsight Compute runs in this
thesis use a fixed ten-counter KPI pack. The profiling scripts in
\texttt{code/profiling/} use exact metric names when available and otherwise
fall back to equivalent names for the installed Nsight Compute version.

\begin{table}[t]
  \centering
  \small
  \begin{tabularx}{\textwidth}{l X}
    \toprule
    ID & Counter selector family (Nsight Compute) \\
    \midrule
    K1 & \texttt{sm\_\_throughput.*pct\_of\_peak} \\
    K2 & \texttt{dram\_\_throughput.*pct\_of\_peak} \\
    K3 & \texttt{lts\_\_...throughput.*pct\_of\_peak} \\
    K4 & \texttt{l1tex\_\_t\_sector\_hit\_rate.pct} \\
    K5 & \texttt{smsp\_\_pipe\_fma\_cycles\_active.*pct\_of\_peak} \\
    K6 & \texttt{sm\_\_warps\_active.*pct\_of\_peak} \\
    K7 & \texttt{launch\_\_occupancy\_limit\_registers} \\
    K8 & \texttt{smsp\_\_warps\_eligible.*per\_cycle\_active} \\
    K9 & \texttt{smsp\_\_issue\_active.*pct\_of\_peak} \\
    K10 & \texttt{smsp\_\_thread\_inst\_executed\_per\_inst\_executed.*} \\
    \bottomrule
  \end{tabularx}
  \caption{KPI identifier to metric-selector mapping used in profiling scripts.}
  \label{tab:kpi-pack}
\end{table}

\paragraph{Interpretation by KPI.}
\begin{description}
  \item[K1 (SM throughput).] Top-level SM progress indicator for overall
  utilisation trends.
  \item[K2 (DRAM throughput).] HBM pressure and memory-system saturation level.
  \item[K3 (L2 throughput).] L2 traffic pressure; useful to separate L2-limited
  from SM-limited phases.
  \item[K4 (L1 hit rate).] L1/texture locality quality for kernels that route
  through this cache path.
  \item[K5 (FP32 FMA pipe active).] Fraction of peak FP32 arithmetic-pipe
  activity, used as primary compute-efficiency signal.
  \item[K6 (warps active).] Runtime active-warp level (occupancy in execution).
  \item[K7 (register occupancy limit).] Indicates register-file constraints on
  theoretical occupancy.
  \item[K8 (warps eligible per cycle).] Scheduler readiness, i.e.\ how many
  warps are ready to issue each cycle.
  \item[K9 (issue active).] Front-end issue-slot utilisation.
  \item[K10 (thread-inst per inst).] Divergence-sensitive thread participation
  per instruction; a direct SIMT-efficiency signal.
\end{description}

\subsection{Interpretation Rules}

Attribution follows these rules under identical problem sizes and launch
configurations:

\begin{enumerate}
  \item \textbf{Compute-limited pattern:} K1 and K5 are high, while K2/K3 are
  not dominant.
  \item \textbf{Memory-limited pattern:} K2 and/or K3 are high, K8/K9 are
  reduced due to memory waiting, and throughput scales weakly with more FMAs.
  \item \textbf{Occupancy/resource-limited pattern:} K7 indicates a register
  limit and K6 remains below expected active-warp levels.
  \item \textbf{Scheduler starvation pattern:} K8 and K9 drop together,
  indicating insufficient eligible warps or long-latency dependencies.
  \item \textbf{Divergence/predication loss pattern:} K10 decreases while kernel
  time increases under otherwise similar arithmetic work.
\end{enumerate}

\subsection{Application to Diagnostic Pairs}

The same KPI pack is applied to both diagnostic pairs used in this chapter:

\begin{itemize}
  \item \textbf{FP32 GEMM pair (cuBLAS vs naive):} expected separation is high
  K1/K5/K9 for cuBLAS and lower compute-issue efficiency for the naive kernel,
  with different memory-pressure signatures in K2--K4.
  \item \textbf{Warp-divergence pair (uniform vs divergent):} expected
  separation is primarily in K10, with secondary reductions in K8/K9 and
  effective throughput for the divergent variant.
\end{itemize}

\paragraph{Representative measured signatures.}
For the FP32 GEMM diagnostic pair, the measured counters show:
K1 $98.45\%$ (cuBLAS) vs $54.32\%$ (naive),
K5 $98.67\%$ vs $28.05\%$,
K9 $56.15\%$ vs $31.50\%$,
with higher memory pressure in the naive kernel
(K2 $16.54\%$ vs $3.62\%$).
This confirms that the naive kernel is not occupancy-limited (K6 is high) but
issue/compute-efficiency-limited.

For the warp-divergence pair, the key discriminator is K10:
$100\%$ (warp-uniform) vs $50.35\%$ (forced divergent split), matching the
expected half-warp execution efficiency for a lane-based $16/16$ branch split.

This fixed KPI pack reduces ad-hoc profiler exploration and makes profile
evidence directly comparable across optimisation steps.
