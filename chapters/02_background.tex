% Chapter 2: Background

\section{Tensor Networks}\label{sec:tensor-networks}
% What tensors are, tensor diagrams, contraction, MPS/MPO basics
% Let advisors explain this to you first, then write it up

\subsection{Tensor Notation and Diagrams}\label{sec:tensor-notation}

\subsection{Tensor Contraction}\label{sec:tensor-contraction}

\subsection{Tensor Network Structures}\label{sec:tn-structures}
% MPS, PEPS, TTN -- whichever are relevant to the thesis

\section{GPU Architecture}\label{sec:gpu-architecture}

\subsection{Streaming Multiprocessor and Warp Execution}\label{sec:sm-warps}

\subsection{Memory Hierarchy}\label{sec:gpu-memory-hierarchy}
% HBM -> L2 -> Shared Memory / L1 -> Registers
% Bandwidth numbers for V100, A100

\subsection{NVIDIA A100 Ampere Architecture}\label{sec:a100}
% Async copy, 192KB shared mem, 40MB L2, tensor cores
% Only features you actually use

\section{CUDA Programming Model}\label{sec:cuda}

\subsection{Thread Hierarchy and Kernel Launch}\label{sec:cuda-threads}

\subsection{Shared Memory and Synchronisation}\label{sec:shared-memory}

\subsection{Memory Coalescing and Bank Conflicts}\label{sec:coalescing}

\subsection{Performance Profiling with Nsight Compute}\label{sec:nsight}

\section{Related Work}\label{sec:related-work}

\subsection{cuBLAS and cuTENSOR}\label{sec:cublas-cutensor}

\subsection{ChASE Eigensolver}\label{sec:chase}
% Your advisors' library -- context for your work

\subsection{Existing GPU Tensor Network Implementations}\label{sec:existing-tn-gpu}
