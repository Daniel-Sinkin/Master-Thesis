
\section{Target Kernels}\label{sec:target-kernels}

The target workload is defined by contraction patterns that can be reduced to
dense linear algebra kernels after index permutation and reshaping. We focus on
kernel classes that are both frequent in tensor-network workflows and sensitive
to GPU execution overhead:

\begin{enumerate}
  \item \textbf{Small/medium GEMM-like contractions} (single and batched),
    including cases where dimensions are not multiples of warp tile sizes.
  \item \textbf{Layout-transformation kernels} (permute/pack/unpack) required
    before and after contractions.
  \item \textbf{Fused kernel sequences} that execute several contractions (and
    optional lightweight post-processing) inside one launch.
\end{enumerate}

The baseline precision target is FP32 for compute and storage, with optional
TF32 tensor-core execution where numerical tolerance permits it. FP64 remains a
reference configuration for accuracy and performance comparison.

\subsection{Selection Criteria}

A kernel is included in the optimisation set if it satisfies at least two of
the following conditions:

\begin{itemize}
  \item high call frequency in representative traces,
  \item measurable contribution to end-to-end runtime,
  \item clear exposure to launch overhead or memory-traffic bottlenecks,
  \item portability to both single-GPU and one-node multi-GPU execution.
\end{itemize}

\subsection{SOTA-Informed Initial Backlog (Working Notes)}
\label{sec:initial-backlog}

Before full application traces are fixed, the optimisation backlog is organised
as a set of generic kernel classes that repeatedly appear in the cited
literature and in early profiling:

\begin{enumerate}
  \item \textbf{Shape-bucketed small GEMM path.} Group contractions by
    $(m,n,k)$ class and run batched/device-side execution to reduce launch
    count.
  \item \textbf{Layout-heavy micro-pipeline path.} Fuse reshape/pack/contract
    segments when data dependencies allow it, and track whether reduced launch
    count offsets higher register/shared-memory pressure.
  \item \textbf{Local-operator-sum contraction path.} Prefer execution plans
    that avoid explicit large intermediate operators when equivalent local-term
    accumulation is available.
\end{enumerate}

For each class, the first profiling pass records the same minimum metric set:
kernel runtime, launch count, achieved occupancy, DRAM throughput, and top warp
stall reasons. This keeps early optimisation choices comparable even before the
final production kernel list is fixed.
