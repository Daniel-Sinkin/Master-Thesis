\babel@toc {english}{}\relax 
\contentsline {chapter}{Abstract}{iii}{chapter*.1}%
\contentsline {chapter}{Acknowledgements}{v}{chapter*.2}%
\contentsline {chapter}{\nonumberline List of Figures}{ix}{chapter*.4}%
\contentsline {chapter}{\nonumberline List of Tables}{xi}{chapter*.5}%
\contentsline {chapter}{\nonumberline Listings}{xiii}{chapter*.6}%
\contentsline {chapter}{List of Symbols}{xv}{chapter*.7}%
\contentsline {chapter}{List of Abbreviations}{xvii}{chapter*.8}%
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Problem Statement}{1}{section.1.2}%
\contentsline {section}{\numberline {1.3}Contributions}{1}{section.1.3}%
\contentsline {section}{\numberline {1.4}Outline}{1}{section.1.4}%
\contentsline {chapter}{\numberline {2}Background}{3}{chapter.2}%
\contentsline {section}{\numberline {2.1}Tensor Networks}{3}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Tensor Notation and Diagrams}{3}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Tensor Contraction}{3}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Tensor Network Structures}{3}{subsection.2.1.3}%
\contentsline {section}{\numberline {2.2}GPU Architecture}{3}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Streaming Multiprocessor and Warp Execution}{3}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Floating-Point Formats and Precision Trade-offs}{3}{subsection.2.2.2}%
\contentsline {subsubsection}{\nonumberline IEEE 754 Binary Representation}{3}{subsubsection*.10}%
\contentsline {subsubsection}{\nonumberline A100 Throughput by Precision}{5}{subsubsection*.15}%
\contentsline {subsubsection}{\nonumberline The Case for Single Precision in Tensor Network Computations}{5}{subsubsection*.18}%
\contentsline {subsection}{\numberline {2.2.3}Memory Hierarchy}{6}{subsection.2.2.3}%
\contentsline {paragraph}{\nonumberline GPU Memory Hierarchy}{7}{figure.caption.22}%
\contentsline {subsection}{\numberline {2.2.4}NVIDIA A100 Ampere Architecture}{7}{subsection.2.2.4}%
\contentsline {subsubsection}{\nonumberline Hardware Overview}{7}{subsubsection*.24}%
\contentsline {subsubsection}{\nonumberline Theoretical Peak Performance}{8}{subsubsection*.27}%
\contentsline {subsubsection}{\nonumberline Derived Performance Limits}{8}{subsubsection*.30}%
\contentsline {subsubsection}{\nonumberline Memory Latency}{8}{subsubsection*.33}%
\contentsline {subsection}{\numberline {2.2.5}Compute Node Topology}{8}{subsection.2.2.5}%
\contentsline {subsubsection}{\nonumberline CPU and NUMA Topology}{8}{subsubsection*.36}%
\contentsline {subsubsection}{\nonumberline GPU Interconnect Topology}{10}{subsubsection*.39}%
\contentsline {section}{\numberline {2.3}CUDA Programming Model}{11}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Thread Hierarchy and Kernel Launch}{11}{subsection.2.3.1}%
\contentsline {subsubsection}{\nonumberline Kernel Syntax and Launch Configuration}{12}{subsubsection*.44}%
\contentsline {subsubsection}{\nonumberline Two-Dimensional Grid Addressing}{12}{subsubsection*.46}%
\contentsline {subsubsection}{\nonumberline Block Size Selection and Hardware Constraints}{13}{subsubsection*.48}%
\contentsline {subsubsection}{\nonumberline Linearisation of Multidimensional Indices}{13}{subsubsection*.50}%
\contentsline {subsection}{\numberline {2.3.2}Shared Memory and Synchronisation}{14}{subsection.2.3.2}%
\contentsline {subsubsection}{\nonumberline Static and Dynamic Allocation}{14}{subsubsection*.52}%
\contentsline {subsubsection}{\nonumberline Tiled Matrix Multiplication}{14}{subsubsection*.54}%
\contentsline {subsection}{\numberline {2.3.3}Memory Coalescing and Bank Conflicts}{16}{subsection.2.3.3}%
\contentsline {subsubsection}{\nonumberline Global Memory Coalescing}{16}{subsubsection*.56}%
\contentsline {subsubsection}{\nonumberline Shared Memory Bank Conflicts}{16}{subsubsection*.58}%
\contentsline {subsection}{\numberline {2.3.4}Performance Profiling with Nsight Compute}{17}{subsection.2.3.4}%
\contentsline {section}{\numberline {2.4}Related Work}{18}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}cuBLAS and cuTENSOR}{18}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}ChASE Eigensolver}{18}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Existing GPU Tensor Network Implementations}{18}{subsection.2.4.3}%
\contentsline {chapter}{\numberline {3}Design and Methodology}{19}{chapter.3}%
\contentsline {section}{\numberline {3.1}Target Kernels}{19}{section.3.1}%
\contentsline {section}{\numberline {3.2}Algorithmic Approach}{19}{section.3.2}%
\contentsline {section}{\numberline {3.3}Data Layout and Memory Strategy}{19}{section.3.3}%
\contentsline {section}{\numberline {3.4}Baseline Selection}{19}{section.3.4}%
\contentsline {chapter}{\numberline {4}Implementation}{21}{chapter.4}%
\contentsline {section}{\numberline {4.1}Kernel Design}{21}{section.4.1}%
\contentsline {section}{\numberline {4.2}Shared Memory Tiling}{21}{section.4.2}%
\contentsline {section}{\numberline {4.3}Occupancy and Launch Configuration}{21}{section.4.3}%
\contentsline {section}{\numberline {4.4}Integration and Build System}{21}{section.4.4}%
\contentsline {chapter}{\numberline {5}Results}{23}{chapter.5}%
\contentsline {section}{\numberline {5.1}Experimental Setup}{23}{section.5.1}%
\contentsline {section}{\numberline {5.2}Single-GPU Performance}{23}{section.5.2}%
\contentsline {section}{\numberline {5.3}Profiling Analysis}{23}{section.5.3}%
\contentsline {section}{\numberline {5.4}Comparison with cuBLAS and cuTENSOR}{23}{section.5.4}%
\contentsline {section}{\numberline {5.5}Scaling Behaviour}{23}{section.5.5}%
\contentsline {section}{\numberline {5.6}Discussion}{23}{section.5.6}%
\contentsline {chapter}{\numberline {6}Conclusion}{25}{chapter.6}%
\contentsline {section}{\numberline {6.1}Summary}{25}{section.6.1}%
\contentsline {section}{\numberline {6.2}Limitations}{25}{section.6.2}%
\contentsline {section}{\numberline {6.3}Future Work}{25}{section.6.3}%
\contentsline {chapter}{\nonumberline Bibliography}{27}{chapter*.59}%
\contentsline {chapter}{\numberline {7}Experimental Environment and Reproducibility}{31}{chapter.7}%
\contentsline {section}{\numberline {7.1}Hardware Configuration}{31}{section.7.1}%
\contentsline {section}{\numberline {7.2}Software Environment}{32}{section.7.2}%
\contentsline {section}{\numberline {7.3}GPU Topology}{32}{section.7.3}%
\contentsline {section}{\numberline {7.4}Build and Run Procedure}{33}{section.7.4}%
\contentsline {section}{\numberline {7.5}Measurement Methodology}{33}{section.7.5}%
\contentsline {section}{\numberline {7.6}Data Availability}{33}{section.7.6}%
\contentsline {chapter}{\numberline {A}Supplementary Benchmarks}{35}{appendix.A}%
\contentsline {chapter}{Declaration of Authorship}{37}{chapter*.64}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
