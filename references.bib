@inproceedings{wu2023chase-nccl,
  author    = {Wu, Xinzhe and Di~Napoli, Edoardo},
  title     = {Advancing the distributed Multi-{GPU} {ChASE} library through
               algorithm optimization and {NCCL} library},
  booktitle = {Workshops of The International Conference on High Performance
               Computing, Network, Storage, and Analysis (SC-W~'23)},
  year      = {2023},
  pages     = {1688--1696},
  publisher = {ACM},
  doi       = {10.1145/3624062.3624249},
}

@inproceedings{wu2022chase-gpu,
  author    = {Wu, Xinzhe and Davidovi\'{c}, Davor and Achilles, Sebastian
               and Di~Napoli, Edoardo},
  title     = {{ChASE}: a distributed hybrid {CPU-GPU} eigensolver for
               large-scale hermitian eigenvalue problems},
  booktitle = {Proceedings of the Platform for Advanced Scientific Computing
               Conference (PASC~'22)},
  year      = {2022},
  pages     = {1--12},
  publisher = {ACM},
  doi       = {10.1145/3539781.3539792},
}

@article{winkelmann2019chase,
  author  = {Winkelmann, Jan and Springer, Paul and Di~Napoli, Edoardo},
  title   = {{ChASE}: {C}hebyshev Accelerated Subspace iteration Eigensolver
             for sequences of {H}ermitian eigenvalue problems},
  journal = {ACM Transactions on Mathematical Software},
  volume  = {45},
  number  = {2},
  pages   = {1--34},
  year    = {2019},
  doi     = {10.1145/3313828},
}

@phdthesis{wu2019phd,
  author = {Wu, Xinzhe},
  title  = {Contribution to the Emergence of New Intelligent Parallel and
            Distributed Methods Using a Multi-level Programming Paradigm
            for Extreme Computing},
  school = {University of Lille},
  year   = {2019},
}

@manual{nvidia2020a100,
  author = {{NVIDIA Corporation}},
  title  = {{NVIDIA} {A100} Tensor Core {GPU} Architecture},
  year   = {2020},
  note   = {Whitepaper v1.0},
}

@manual{nvidia2022h100,
  author = {{NVIDIA Corporation}},
  title  = {{NVIDIA} {H100} Tensor Core {GPU} Architecture},
  year   = {2022},
  note   = {Whitepaper},
}

@manual{nvidia-cuda-guide,
  author = {{NVIDIA Corporation}},
  title  = {{CUDA} {C}++ Programming Guide},
  year   = {2024},
  note   = {\url{https://docs.nvidia.com/cuda/cuda-c-programming-guide/}},
}

@misc{cutensor,
  author = {{NVIDIA Corporation}},
  title  = {{cuTENSOR}: A High-Performance Tensor Primitives Library},
  year   = {2024},
  note   = {\url{https://developer.nvidia.com/cutensor}},
}

@misc{cublas,
  author = {{NVIDIA Corporation}},
  title  = {{cuBLAS} Library},
  year   = {2024},
  note   = {\url{https://developer.nvidia.com/cublas}},
}

@misc{cublasdx,
  author = {{NVIDIA Corporation}},
  title  = {{cuBLASDx}: Device Side {BLAS} Extensions},
  year   = {2025},
  note   = {\url{https://docs.nvidia.com/cuda/cublasdx/}},
}

@inproceedings{springer2017tensor,
  author    = {Springer, Paul and Su, Tong and Kolda, Tamara G.},
  title     = {Tensor Contractions with Extended {BLAS} Kernels on {CPU} and {GPU}},
  booktitle = {IEEE 24th International Conference on High Performance Computing (HiPC)},
  year      = {2017},
  publisher = {IEEE},
  note      = {\url{https://research.nvidia.com/sites/default/files/pubs/2017-10_Tensor-Contractions-with/tensors_hipc.pdf}},
}

@misc{boehm2022cuda-mmm,
  author = {Boehm, Simon},
  title  = {How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog},
  year   = {2022},
  note   = {\url{https://siboehm.com/articles/22/CUDA-MMM}},
}

@article{white1992dmrg,
  author  = {White, Steven R.},
  title   = {Density Matrix Formulation for Quantum Renormalization Groups},
  journal = {Physical Review Letters},
  volume  = {69},
  number  = {19},
  pages   = {2863--2866},
  year    = {1992},
  doi     = {10.1103/PhysRevLett.69.2863},
}

@article{white1993dmrg,
  author  = {White, Steven R.},
  title   = {Density-Matrix Algorithms for Quantum Renormalization Groups},
  journal = {Physical Review B},
  volume  = {48},
  number  = {14},
  pages   = {10345--10356},
  year    = {1993},
  doi     = {10.1103/PhysRevB.48.10345},
}

@article{schollwock2011dmrg,
  author  = {Schollw\"ock, Ulrich},
  title   = {The Density-Matrix Renormalization Group in the Age of Matrix Product States},
  journal = {Annals of Physics},
  volume  = {326},
  number  = {1},
  pages   = {96--192},
  year    = {2011},
  doi     = {10.1016/j.aop.2010.09.012},
}

@article{orus2014practical-intro-tn,
  author  = {Orus, Roman},
  title   = {A Practical Introduction to Tensor Networks: Matrix Product States and Projected Entangled Pair States},
  journal = {Annals of Physics},
  volume  = {349},
  pages   = {117--158},
  year    = {2014},
  doi     = {10.1016/j.aop.2014.06.013},
}

@misc{nvidia2020gtc-ampere,
author       = {Ramirez, Ronny and Hsu, William},
title        = {Optimizing Applications for {NVIDIA} {Ampere} {GPU} Architecture},
howpublished = {GTC 2020, Session S21819},
year         = {2020},
note         = {\url{https://developer.download.nvidia.com/video/gputechconf/gtc/2020/presentations/s21819-optimizing-applications-for-nvidia-ampere-gpu-architecture.pdf}},
}

@manual{nvidia-ampere-tuning-guide,
  author = {{NVIDIA Corporation}},
  title  = {{NVIDIA} Ampere {GPU} Architecture Tuning Guide},
  year   = {2025},
  note   = {\url{https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html}},
}

@manual{nvidia-cuda-best-practices,
  author = {{NVIDIA Corporation}},
  title  = {{CUDA} {C}++ Best Practices Guide},
  year   = {2025},
  note   = {\url{https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/}},
}

@manual{nvidia-nsight-compute-profiling-guide,
  author = {{NVIDIA Corporation}},
  title  = {{NVIDIA} Nsight Compute Profiling Guide},
  year   = {2025},
  note   = {\url{https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html}},
}

@manual{nvidia-nsight-systems-user-guide,
  author = {{NVIDIA Corporation}},
  title  = {{NVIDIA} Nsight Systems User Guide},
  year   = {2025},
  note   = {\url{https://docs.nvidia.com/nsight-systems/UserGuide/index.html}},
}

@manual{nvidia-smi-doc,
  author = {{NVIDIA Corporation}},
  title  = {{NVIDIA} System Management Interface ({nvidia-smi})},
  year   = {2025},
  note   = {\url{https://docs.nvidia.com/deploy/nvidia-smi/index.html}},
}

@manual{spec-cpu2017-runrules,
  author = {{SPEC Open Systems Group}},
  title  = {{SPEC} {CPU}2017 Run and Reporting Rules},
  year   = {2021},
  note   = {\url{https://www.spec.org/cpu2017/Docs/runrules.html}},
}

@inproceedings{kalibera2013rigorous,
  author    = {Kalibera, Tomas and Jones, Richard},
  title     = {Rigorous Benchmarking in Reasonable Time},
  booktitle = {Proceedings of the International Symposium on Memory Management (ISMM)},
  year      = {2013},
  pages     = {63--74},
  publisher = {ACM},
  doi       = {10.1145/2464157.2464160},
}

@inproceedings{mytkowicz2009wrongdata,
  author    = {Mytkowicz, Todd and Diwan, Amer and Hauswirth, Matthias and
               Sweeney, Peter F.},
  title     = {Producing Wrong Data Without Doing Anything Obviously Wrong!},
  booktitle = {Proceedings of the International Conference on Architectural
               Support for Programming Languages and Operating Systems (ASPLOS)},
  year      = {2009},
  pages     = {265--276},
  publisher = {ACM},
  doi       = {10.1145/1508284.1508275},
}

@article{fleming1986geomean,
  author  = {Fleming, Philip J. and Wallace, John J.},
  title   = {How Not to Lie with Statistics: The Correct Way to Summarize Benchmark Results},
  journal = {Communications of the ACM},
  volume  = {29},
  number  = {3},
  pages   = {218--221},
  year    = {1986},
  doi     = {10.1145/5666.5673},
}

@misc{ieee754-2019,
  author    = {{IEEE}},
  title     = {{IEEE} Standard for Floating-Point Arithmetic},
  number    = {754-2019},
  year      = {2019},
  publisher = {IEEE},
  doi       = {10.1109/IEEESTD.2019.8766229},
}

@inproceedings{kalamkar2019bfloat16,
  author    = {Kalamkar, Dhiraj and Mudigere, Dheevatsa and Mellempudi,
               Naveen and Das, Dipankar and Banerjee, Kunal and
               Avancha, Sasikanth and Vooturi, Dharma Teja and
               Jammalamadaka, Nataraj and Huang, Jianyu and
               Yuen, Hector and others},
  title     = {A Study of {BFLOAT16} for Deep Learning Training},
  booktitle = {arXiv preprint arXiv:1905.12322},
  year      = {2019},
}

@article{higham2022mixed,
  author  = {Higham, Nicholas J. and Mary, Theo},
  title   = {Mixed Precision Algorithms in Numerical Linear Algebra},
  journal = {Acta Numerica},
  volume  = {31},
  pages   = {347--414},
  year    = {2022},
  doi     = {10.1017/S0962492922000022},
}

@book{hockney1988parallel,
  author    = {Hockney, R. W. and Jesshope, C. R.},
  title     = {Parallel Computers 2: Architecture, Programming and Algorithms},
  publisher = {Adam Hilger},
  year      = {1988},
}

@misc{nvidia-nsight-latency,
  author       = {Purnomo, Budirijanto},
  title        = {Understanding the Visualization of Overhead and Latency in
                  {NVIDIA} {Nsight} Systems},
  howpublished = {NVIDIA Technical Blog},
  year         = {2024},
  note         = {\url{https://developer.nvidia.com/blog/understanding-the-visualization-of-overhead-and-latency-in-nsight-systems/}},
}

@inproceedings{gilman2020placement,
  author    = {Gilman, Elijah and Walls, Samuel and Merritt, Alexander
               and Ward, Bryan C.},
  title     = {Demystifying the Placement Policies of the {NVIDIA} {GPU}
               Thread Block Scheduler},
  booktitle = {Proceedings of the International Conference on Real-Time
               Networks and Systems (RTNS)},
  year      = {2020},
  publisher = {ACM},
  note      = {\url{https://cake.wpi.edu/assets/papers/gilman20_performance.pdf}},
}

@article{menczer2023massive,
  author  = {Menczer, Tamas and Legeza, Ors and others},
  title   = {Massively Parallel Tensor Network State Algorithms on Hybrid
             {CPU-GPU} Based Architectures},
  journal = {arXiv preprint arXiv:2305.05581},
  year    = {2023},
  note    = {\url{https://arxiv.org/abs/2305.05581}},
}

@article{menczer2023nonabelian,
  author  = {Menczer, Tamas and Legeza, Ors and others},
  title   = {Boosting the effective performance of massively parallel tensor
             network state algorithms on hybrid {CPU-GPU} based architectures
             via non-{A}belian symmetries},
  journal = {arXiv preprint arXiv:2309.16724},
  year    = {2023},
  note    = {\url{https://arxiv.org/abs/2309.16724}},
}

@article{menczer2024efficient-dmrg-gpu,
  author  = {Menczer, Tamas and Legeza, Ors and others},
  title   = {Parallel implementation of the Density Matrix Renormalization
             Group method achieving a quarter petaFLOPS performance on a single
             {DGX-H100} {GPU} node},
  journal = {arXiv preprint arXiv:2407.07411},
  year    = {2024},
  note    = {\url{https://arxiv.org/abs/2407.07411}},
}

@article{krinitsin2025ttn-ed,
  author  = {Krinitsin, Aleksei V. and Rizzi, Matteo and Waintal, Xavier},
  title   = {Time evolution of the quantum Ising model in two dimensions using
             tree tensor networks},
  journal = {arXiv preprint arXiv:2505.07612},
  year    = {2025},
  note    = {\url{https://arxiv.org/abs/2505.07612}},
}

@article{zhou2020limits,
  author  = {Zhou, Shangnan and Stoudenmire, E. Miles and Waintal, Xavier},
  title   = {What Limits the Simulation of Quantum Computers?},
  journal = {Physical Review X},
  volume  = {10},
  number  = {4},
  pages   = {041038},
  year    = {2020},
  doi     = {10.1103/PhysRevX.10.041038},
  note    = {\url{https://arxiv.org/abs/2002.07730}},
}

@article{ayral2023dmrg-circuit-fidelity,
  author  = {Ayral, Thomas and others},
  title   = {Density Matrix Renormalization Group Algorithm for Simulating
             Quantum Circuits with a Finite Fidelity},
  journal = {PRX Quantum},
  volume  = {4},
  number  = {3},
  pages   = {030307},
  year    = {2023},
  doi     = {10.1103/PRXQuantum.4.030307},
  note    = {\url{https://arxiv.org/abs/2302.01941}},
}
