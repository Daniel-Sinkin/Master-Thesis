@inproceedings{wu2023chase-nccl,
  author    = {Wu, Xinzhe and Di~Napoli, Edoardo},
  title     = {Advancing the distributed Multi-{GPU} {ChASE} library through
               algorithm optimization and {NCCL} library},
  booktitle = {Workshops of The International Conference on High Performance
               Computing, Network, Storage, and Analysis (SC-W~'23)},
  year      = {2023},
  pages     = {1688--1696},
  publisher = {ACM},
  doi       = {10.1145/3624062.3624249},
}

@inproceedings{wu2022chase-gpu,
  author    = {Wu, Xinzhe and Davidovi\'{c}, Davor and Achilles, Sebastian
               and Di~Napoli, Edoardo},
  title     = {{ChASE}: a distributed hybrid {CPU-GPU} eigensolver for
               large-scale hermitian eigenvalue problems},
  booktitle = {Proceedings of the Platform for Advanced Scientific Computing
               Conference (PASC~'22)},
  year      = {2022},
  pages     = {1--12},
  publisher = {ACM},
  doi       = {10.1145/3539781.3539792},
}

@article{winkelmann2019chase,
  author  = {Winkelmann, Jan and Springer, Paul and Di~Napoli, Edoardo},
  title   = {{ChASE}: {C}hebyshev Accelerated Subspace iteration Eigensolver
             for sequences of {H}ermitian eigenvalue problems},
  journal = {ACM Transactions on Mathematical Software},
  volume  = {45},
  number  = {2},
  pages   = {1--34},
  year    = {2019},
  doi     = {10.1145/3313828},
}

@phdthesis{wu2019phd,
  author = {Wu, Xinzhe},
  title  = {Contribution to the Emergence of New Intelligent Parallel and
            Distributed Methods Using a Multi-level Programming Paradigm
            for Extreme Computing},
  school = {University of Lille},
  year   = {2019},
}

@manual{nvidia2020a100,
  author = {{NVIDIA Corporation}},
  title  = {{NVIDIA} {A100} Tensor Core {GPU} Architecture},
  year   = {2020},
  note   = {Whitepaper v1.0},
}

@manual{nvidia2022h100,
  author = {{NVIDIA Corporation}},
  title  = {{NVIDIA} {H100} Tensor Core {GPU} Architecture},
  year   = {2022},
  note   = {Whitepaper},
}

@manual{nvidia-cuda-guide,
  author = {{NVIDIA Corporation}},
  title  = {{CUDA} {C}++ Programming Guide},
  year   = {2024},
  note   = {\url{https://docs.nvidia.com/cuda/cuda-c-programming-guide/}},
}

@misc{cutensor,
  author = {{NVIDIA Corporation}},
  title  = {{cuTENSOR}: A High-Performance Tensor Primitives Library},
  year   = {2024},
  note   = {\url{https://developer.nvidia.com/cutensor}},
}

@misc{cublas,
  author = {{NVIDIA Corporation}},
  title  = {{cuBLAS} Library},
  year   = {2024},
  note   = {\url{https://developer.nvidia.com/cublas}},
}

@misc{cublasdx,
  author = {{NVIDIA Corporation}},
  title  = {{cuBLASDx}: Device Side {BLAS} Extensions},
  year   = {2025},
  note   = {\url{https://docs.nvidia.com/cuda/cublasdx/}},
}

@inproceedings{springer2017tensor,
  author    = {Springer, Paul and Su, Tong and Kolda, Tamara G.},
  title     = {Tensor Contractions with Extended {BLAS} Kernels on {CPU} and {GPU}},
  booktitle = {IEEE 24th International Conference on High Performance Computing (HiPC)},
  year      = {2017},
  publisher = {IEEE},
  note      = {\url{https://research.nvidia.com/sites/default/files/pubs/2017-10_Tensor-Contractions-with/tensors_hipc.pdf}},
}

@misc{nvidia2020gtc-ampere,
author       = {Ramirez, Ronny and Hsu, William},
title        = {Optimizing Applications for {NVIDIA} {Ampere} {GPU} Architecture},
howpublished = {GTC 2020, Session S21819},
year         = {2020},
note         = {\url{https://developer.download.nvidia.com/video/gputechconf/gtc/2020/presentations/s21819-optimizing-applications-for-nvidia-ampere-gpu-architecture.pdf}},
}

@misc{ieee754-2019,
  author    = {{IEEE}},
  title     = {{IEEE} Standard for Floating-Point Arithmetic},
  number    = {754-2019},
  year      = {2019},
  publisher = {IEEE},
  doi       = {10.1109/IEEESTD.2019.8766229},
}

@inproceedings{kalamkar2019bfloat16,
  author    = {Kalamkar, Dhiraj and Mudigere, Dheevatsa and Mellempudi,
               Naveen and Das, Dipankar and Banerjee, Kunal and
               Avancha, Sasikanth and Vooturi, Dharma Teja and
               Jammalamadaka, Nataraj and Huang, Jianyu and
               Yuen, Hector and others},
  title     = {A Study of {BFLOAT16} for Deep Learning Training},
  booktitle = {arXiv preprint arXiv:1905.12322},
  year      = {2019},
}

@article{higham2022mixed,
  author  = {Higham, Nicholas J. and Mary, Theo},
  title   = {Mixed Precision Algorithms in Numerical Linear Algebra},
  journal = {Acta Numerica},
  volume  = {31},
  pages   = {347--414},
  year    = {2022},
  doi     = {10.1017/S0962492922000022},
}

@misc{nvidia-nsight-latency,
  author       = {Purnomo, Budirijanto},
  title        = {Understanding the Visualization of Overhead and Latency in
                  {NVIDIA} {Nsight} Systems},
  howpublished = {NVIDIA Technical Blog},
  year         = {2024},
  note         = {\url{https://developer.nvidia.com/blog/understanding-the-visualization-of-overhead-and-latency-in-nsight-systems/}},
}

@inproceedings{gilman2020placement,
  author    = {Gilman, Elijah and Walls, Samuel and Merritt, Alexander
               and Ward, Bryan C.},
  title     = {Demystifying the Placement Policies of the {NVIDIA} {GPU}
               Thread Block Scheduler},
  booktitle = {Proceedings of the International Conference on Real-Time
               Networks and Systems (RTNS)},
  year      = {2020},
  publisher = {ACM},
  note      = {\url{https://cake.wpi.edu/assets/papers/gilman20_performance.pdf}},
}

@article{menczer2023massive,
  author  = {Menczer, Tamas and Legeza, Ors and others},
  title   = {Massively parallel tensor network state algorithms on {CPU-GPU}
             architectures},
  journal = {arXiv preprint arXiv:2305.05581},
  year    = {2023},
  note    = {\url{https://arxiv.org/abs/2305.05581}},
}

@article{menczer2023nonabelian,
  author  = {Menczer, Tamas and Legeza, Ors and others},
  title   = {Massively parallel implementation and approaches to simulate
             non-{A}belian quantum lattice models},
  journal = {arXiv preprint arXiv:2309.16724},
  year    = {2023},
  note    = {\url{https://arxiv.org/abs/2309.16724}},
}

@article{menczer2024efficient-dmrg-gpu,
  author  = {Menczer, Tamas and Legeza, Ors and others},
  title   = {Efficient implementation and tuning ideas of future real-space
             parallel {DMRG} calculations based on mixed precision and tensor
             core acceleration},
  journal = {arXiv preprint arXiv:2407.07411},
  year    = {2024},
  note    = {\url{https://arxiv.org/abs/2407.07411}},
}

@article{krinitsin2025ttn-ed,
  author  = {Krinitsin, Aleksei V. and Rizzi, Matteo and Waintal, Xavier},
  title   = {Benchmarking tree tensor network and exact diagonalization methods
             on spin-1/2 and spin-1 models with local operator sums},
  journal = {arXiv preprint arXiv:2505.07612},
  year    = {2025},
  note    = {\url{https://arxiv.org/abs/2505.07612}},
}

@article{zhou2020limits,
  author  = {Zhou, Shangnan and Stoudenmire, E. Miles and Waintal, Xavier},
  title   = {What Limits the Simulation of Quantum Computers?},
  journal = {Physical Review X},
  volume  = {10},
  number  = {4},
  pages   = {041038},
  year    = {2020},
  doi     = {10.1103/PhysRevX.10.041038},
  note    = {\url{https://arxiv.org/abs/2002.07730}},
}

@article{ayral2023dmrg-circuit-fidelity,
  author  = {Ayral, Thomas and others},
  title   = {Density Matrix Renormalization Group Algorithm for Simulating
             Quantum Circuits with a Finite Fidelity},
  journal = {PRX Quantum},
  volume  = {4},
  number  = {3},
  pages   = {030307},
  year    = {2023},
  doi     = {10.1103/PRXQuantum.4.030307},
  note    = {\url{https://arxiv.org/abs/2302.01941}},
}
